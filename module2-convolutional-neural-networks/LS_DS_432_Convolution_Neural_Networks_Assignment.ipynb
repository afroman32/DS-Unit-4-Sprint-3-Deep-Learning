{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/afroman32/DS-Unit-4-Sprint-3-Deep-Learning/blob/main/module2-convolutional-neural-networks/LS_DS_432_Convolution_Neural_Networks_Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fc4yMj7mtCAZ"
   },
   "source": [
    "\n",
    "\n",
    "## *Data Science Unit 4 Sprint 3 Assignment 2*\n",
    "# Convolutional Neural Networks (CNNs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0lfZdD_cp1t5"
   },
   "source": [
    "# Assignment\n",
    "\n",
    "- <a href=\"#p1\">Part 1:</a> Pre-Trained Model\n",
    "- <a href=\"#p2\">Part 2:</a> Custom CNN Model\n",
    "- <a href=\"#p3\">Part 3:</a> CNN with Data Augmentation\n",
    "\n",
    "\n",
    "You will apply three different CNN models to a binary image classification model using Keras. Classify images of Mountains (`./data/train/mountain/*`) and images of forests (`./data/train/forest/*`). Treat mountains as the positive class (1) and the forest images as the negative (zero). \n",
    "\n",
    "|Mountain (+)|Forest (-)|\n",
    "|---|---|\n",
    "|![](https://github.com/LambdaSchool/DS-Unit-4-Sprint-3-Deep-Learning/blob/main/module2-convolutional-neural-networks/data/train/mountain/art1131.jpg?raw=1)|![](https://github.com/LambdaSchool/DS-Unit-4-Sprint-3-Deep-Learning/blob/main/module2-convolutional-neural-networks/data/validation/forest/cdmc317.jpg?raw=1)|\n",
    "\n",
    "The problem is relatively difficult given that the sample is tiny: there are about 350 observations per class. This sample size might be something that you can expect when prototyping an image classification problem/solution at work. Get accustomed to evaluating several different possible models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1eawBP-otCAb"
   },
   "source": [
    "# Pre - Trained Model\n",
    "<a id=\"p1\"></a>\n",
    "\n",
    "Load a pretrained network from Keras, [ResNet50](https://tfhub.dev/google/imagenet/resnet_v1_50/classification/1) - a 50 layer deep network trained to recognize [1000 objects](https://storage.googleapis.com/download.tensorflow.org/data/ImageNetLabels.txt). Starting usage:\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model # This is the functional API\n",
    "\n",
    "resnet = ResNet50(weights='imagenet', include_top=False)\n",
    "\n",
    "```\n",
    "\n",
    "The `include_top` parameter in `ResNet50` will remove the full connected layers from the ResNet model. The next step is to turn off the training of the ResNet layers. We want to use the learned parameters without updating them in future training passes. \n",
    "\n",
    "```python\n",
    "for layer in resnet.layers:\n",
    "    layer.trainable = False\n",
    "```\n",
    "\n",
    "Using the Keras functional API, we will need to additional additional full connected layers to our model. We we removed the top layers, we removed all preivous fully connected layers. In other words, we kept only the feature processing portions of our network. You can expert with additional layers beyond what's listed here. The `GlobalAveragePooling2D` layer functions as a really fancy flatten function by taking the average of each of the last convolutional layer outputs (which is two dimensional still). \n",
    "\n",
    "```python\n",
    "x = resnet.output\n",
    "x = GlobalAveragePooling2D()(x) # This layer is a really fancy flatten\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "predictions = Dense(1, activation='sigmoid')(x)\n",
    "model = Model(resnet.input, predictions)\n",
    "```\n",
    "\n",
    "Your assignment is to apply the transfer learning above to classify images of Mountains (`./data/train/mountain/*`) and images of forests (`./data/train/forest/*`). Treat mountains as the positive class (1) and the forest images as the negative (zero). \n",
    "\n",
    "Steps to complete assignment: \n",
    "1. Load in Image Data into numpy arrays (`X`) \n",
    "2. Create a `y` for the labels\n",
    "3. Train your model with pre-trained layers from resnet\n",
    "4. Report your model's accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v4vFCIVgyojI"
   },
   "source": [
    "-----\n",
    "\n",
    "# GPU on Colab\n",
    "\n",
    "If you're working on Colab, you only have access to 2 processors so your model training will be slow. However, if you turn on the GPU instance that you have access to then you're model training will be faster! \n",
    "\n",
    "[**Instructions for turning on GPU on Colab**](https://colab.research.google.com/notebooks/gpu.ipynb)\n",
    "\n",
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CLdGdXCatCAb"
   },
   "source": [
    "## Load in Data\n",
    "\n",
    "This surprisingly more difficult than it seems, because you are working with directories of images instead of a single file. \n",
    "\n",
    "This boiler plate will help you download a zipped version of the directory of images. The directory is organized into **train** and **validation** directories which you can use inside an `ImageGenerator` class to stream batches of images through your model.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-BluDZ-syojI"
   },
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model # This is the functional API\n",
    "\n",
    "from tensorflow.keras import datasets\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten\n",
    "\n",
    "from keras.preprocessing.image import array_to_img, img_to_array, load_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YBwb3g6fyojJ"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "exlQ1ZnfyojJ"
   },
   "outputs": [],
   "source": [
    "# Clear any tensorboard logs from previous runs\n",
    "!rm -rf ./logs/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "moRVuHUqtCAc"
   },
   "source": [
    "### Download & Summarize the Data\n",
    "\n",
    "This step is completed for you. Just run the cells and review the results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AR66H8o9tCAc"
   },
   "outputs": [],
   "source": [
    "# data url\n",
    "_URL = 'https://github.com/LambdaSchool/DS-Unit-4-Sprint-3-Deep-Learning/blob/main/module2-convolutional-neural-networks/data.zip?raw=true'\n",
    "\n",
    "# download data and save to `file_name`\n",
    "file_name = './data.zip'\n",
    "path_to_zip = tf.keras.utils.get_file(file_name, origin=_URL, extract=True)\n",
    "\n",
    "# get absolute path to location of the data that we just downloaded\n",
    "PATH = os.path.join(os.path.dirname(path_to_zip), 'data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "yiRkQPFfyojK",
    "outputId": "2370c8a0-6a7c-465d-ab60-737ac2b01fea"
   },
   "outputs": [],
   "source": [
    "# protip: go to your terminal and paste the output below and cd into it\n",
    "# explore it a bit...we'll come back to this later - muahahaha!!!\n",
    "PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MNFsIu_KtCAg"
   },
   "outputs": [],
   "source": [
    "# create train data dir path\n",
    "train_dir = os.path.join(PATH, 'train')\n",
    "\n",
    "# create validation data dir path\n",
    "validation_dir = os.path.join(PATH, 'validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OsI9BQLotCAj"
   },
   "outputs": [],
   "source": [
    "# train directory with mountian data sub-dir \n",
    "train_mountain_dir = os.path.join(train_dir, 'mountain') \n",
    "\n",
    "# train directory with forest data sub-dir \n",
    "train_forest_dir = os.path.join(train_dir, 'forest')  \n",
    "\n",
    "# validation directory with mountain data sub-dir \n",
    "validation_mountain_dir = os.path.join(validation_dir, 'mountain')  \n",
    "\n",
    "# validation directory with forest data sub-dir \n",
    "validation_forest_dir = os.path.join(validation_dir, 'forest')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NUs1e5-XtCAl"
   },
   "outputs": [],
   "source": [
    "# get the number of samples in each of the sub-dir \n",
    "num_mountain_tr = len(os.listdir(train_mountain_dir))\n",
    "num_forest_tr = len(os.listdir(train_forest_dir))\n",
    "\n",
    "num_mountain_val = len(os.listdir(validation_mountain_dir))\n",
    "num_forest_val = len(os.listdir(validation_forest_dir))\n",
    "\n",
    "# get the total numnber of sample for the train and validation sets\n",
    "total_train = num_mountain_tr + num_forest_tr\n",
    "total_val = num_mountain_val + num_forest_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZmklbgSMtCAn",
    "outputId": "142a4dc5-988f-45de-96fb-4dd38f7f8d18"
   },
   "outputs": [],
   "source": [
    "print('total training mountain images:', num_mountain_tr)\n",
    "print('total training forest images:', num_forest_tr)\n",
    "\n",
    "print('total validation mountain images:', num_mountain_val)\n",
    "print('total validation forest images:', num_forest_val)\n",
    "print(\"--\")\n",
    "print(\"Total training images:\", total_train)\n",
    "print(\"Total validation images:\", total_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7Ajz-ibHyojM"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dQ4ag4ultCAq"
   },
   "source": [
    "### Keras `ImageGenerator` to Process the Data\n",
    "\n",
    "This step is completed for you, but please review the code. The `ImageGenerator` class reads in batches of data from a directory and pass them to the model one batch at a time. Just like large text files, this method is advantageous, because it stifles the need to load a bunch of images into memory. \n",
    "\n",
    "**Check out the documentation for this class method:** [**Keras ImageGenerator Class**](https://keras.io/preprocessing/image/#imagedatagenerator-class). You'll expand it's use in the next section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "67i9IW49tCAq"
   },
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "epochs = 10 # feel free to change this value only after you've gone through the notebook once  \n",
    "IMG_HEIGHT = 224\n",
    "IMG_WIDTH = 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B1wNKMo1tCAt"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# ImageDataGenerator can rescale data from within \n",
    "max_pixel_val = 255.\n",
    "rescale = 1./max_pixel_val\n",
    "\n",
    "# Generator for our training data\n",
    "train_image_generator = ImageDataGenerator(rescale=rescale) \n",
    "                                           \n",
    "# Generator for our validation data                                           \n",
    "validation_image_generator = ImageDataGenerator(rescale=rescale) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ndsuM4L9tCAv",
    "outputId": "4767010d-78b3-4ad0-8abb-8576fccdde14"
   },
   "outputs": [],
   "source": [
    "# Takes the path to a directory & generates batches of augmented data\n",
    "train_data_gen = train_image_generator.flow_from_directory(batch_size=batch_size,\n",
    "                                                           directory=train_dir,\n",
    "                                                           shuffle=True,\n",
    "                                                           target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "                                                           class_mode='binary', \n",
    "                                                           color_mode='rgb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NeamkCfxyojM"
   },
   "outputs": [],
   "source": [
    "# explore some of `train_data_gen` attributes to get a sense of what this object can do for you"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9kxlk3optCAy",
    "outputId": "ffad2962-98c3-44f3-ebd1-b868e18b9247"
   },
   "outputs": [],
   "source": [
    "# Takes the path to a directory & generates batches of augmented data\n",
    "val_data_gen = validation_image_generator.flow_from_directory(batch_size=batch_size,\n",
    "                                                              directory=validation_dir,\n",
    "                                                              target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "                                                              class_mode='binary', \n",
    "                                                              color_mode='rgb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4BXKrR6uyojN"
   },
   "outputs": [],
   "source": [
    "# explore some of `val_data_gen` attributes to get a sense of what this object can do for you\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2l7ue6NutCA0"
   },
   "source": [
    "_____\n",
    "## Instantiate Model\n",
    "\n",
    "Here your job is to take the python code in the beginning of the notebook (in the markdown cell) and turn it into working code. \n",
    "\n",
    "Most of the code that you'll need to build a model is in that markdown cell, though you'll still need to compile the model.\n",
    "\n",
    "Some pseudo-code is provided as guide. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "id": "mKNIYOEItCA0",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3ef6aebc8089f2297504b310c583cb98",
     "grade": false,
     "grade_id": "cell-f5f8bf566ce32a9b",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    " \n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    " \n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model # This is the functional API\n",
    " \n",
    "resnet = ResNet50(weights='imagenet', include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "id": "nIgJEJEhyojQ",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "16a5d78e4c810864427217d8846aa811",
     "grade": false,
     "grade_id": "cell-c9ce632ff4dce6bc",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "for layer in resnet.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "id": "HcfvlrYIyojQ",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "93c62210094db18dc989941d624caa9f",
     "grade": false,
     "grade_id": "cell-9ab2a3f78406ccee",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# take the model output layer as a starting point\n",
    "x = resnet.output\n",
    "\n",
    "# take a global average pool\n",
    "x = GlobalAveragePooling2D()(x) # This layer is a really fancy flatten\n",
    "\n",
    "# add a trainable hidden layer with 1024 nodes \n",
    "x = Dense(1024, activation='relu')(x)\n",
    "\n",
    "# add a trainable output layer \n",
    "predictions = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "# put it all together using the Keras's Model api\n",
    "model = Model(resnet.input, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "id": "wGgPGJmjyojQ",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4fb9a9608c3d9bc53d7d570ae4e9eaf9",
     "grade": false,
     "grade_id": "cell-2f47a473b5842014",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# the only code that is missing is the compile method \n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BVPBWYG7tCA2"
   },
   "source": [
    "## Fit Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jnU1JKKVyojR"
   },
   "outputs": [],
   "source": [
    "# include the callback into the fit method\n",
    "# we'll launch tensorboard in the last section\n",
    "logdir = os.path.join(\"logs\", \"resnet_model\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H4XdvWA5tCA3",
    "outputId": "d526a4e6-2c9d-4a01-d93b-edeb855701f3"
   },
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train_data_gen,\n",
    "    steps_per_epoch=total_train // batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=val_data_gen,\n",
    "    validation_steps=total_val // batch_size,\n",
    "    workers=10, # num should be 1 or 2 processors less than the total number of process on your machine\n",
    "    callbacks=[tensorboard_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hXLRYVsjyojR"
   },
   "source": [
    "## Take Away\n",
    "\n",
    "The above task is an exercising in using a pre-trained model in the context of **Transfer Learning**. \n",
    "\n",
    "**Transfer Learning** happens when you take a model that was trained on data set $A$ and applying it on data set $B$ (you may or may not choose to re-train the model.)\n",
    "\n",
    "We loaded in a pre-trained model (meaning the weight values have been optimized in a previous fit), and updated the value of the weights by re-training them. Note that we didn't reset the model weights, what we did was \n",
    "continue their training on a different dataset, our data set. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UPzsgS94tCA5"
   },
   "source": [
    "-----\n",
    "# Custom CNN Model\n",
    "\n",
    "In this step, write and train your own convolutional neural network using Keras. You can use any architecture that suits you as long as it has at least one convolutional and one pooling layer at the beginning of the network - you can add more if you want. \n",
    "\n",
    "**Protip:** You'll be creating a 2nd instance of this same model in the next section. Instead of copying and pasting all this code, just embed it in a function called `def create_model()` that returns a complied model. \n",
    "\n",
    "Free free to reference the custom CNN model that we built together in the guided project. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bqwiNc1lT5Qo",
    "outputId": "aca30677-87dd-45c5-ef78-f78f9d6ef81a"
   },
   "outputs": [],
   "source": [
    "train_data_gen[0][0][1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "id": "a3lE_WVEKwK3",
    "outputId": "31a29791-5928-4bb4-d179-4668b7011bdb"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(train_data_gen[0][0][1]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "id": "hnbJJie3tCA5",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4fe146a54f63df2e46fa8396e93b1532",
     "grade": false,
     "grade_id": "cell-f3d186ae68873264",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    \"\"\"\n",
    "    Since we'll using this model again in the next section, it's useful to create a function \n",
    "    that returns a compiled model.\n",
    "    \"\"\"\n",
    "    \n",
    "    model = Sequential([\n",
    "    Conv2D(32, (3,3), activation='relu', input_shape=(224, 224, 3)),\n",
    "    MaxPooling2D((2,2)),\n",
    "    Conv2D(64, (3,3), activation='relu'),\n",
    "    MaxPooling2D((2,2)),\n",
    "    Flatten(),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(2, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aTXeoZmWyojS"
   },
   "outputs": [],
   "source": [
    "# instantiate a model \n",
    "model = create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2E9YTSHRyojS",
    "outputId": "fbcb4ff8-41c6-4332-9ddb-4349ff213635"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u8Uzk4LjyojS"
   },
   "outputs": [],
   "source": [
    "# include this callback in your fit method\n",
    "# we'll launch tensorboard in the last section\n",
    "logdir = os.path.join(\"logs\", \"baseline_model\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CwM4GsaetCA_",
    "outputId": "bc7381e8-0691-4945-ce19-7777656aaf90"
   },
   "outputs": [],
   "source": [
    "# Fit Model\n",
    "epochs = 10\n",
    "history = model.fit(\n",
    "    train_data_gen,\n",
    "    steps_per_epoch=total_train // batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=val_data_gen,\n",
    "    validation_steps=total_val // batch_size,\n",
    "    workers=-1, # num should be 1 or 2 processors less than the total number of process on your machine \n",
    "    callbacks=[tensorboard_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FNTHjUddtCBB"
   },
   "source": [
    "------\n",
    "# Custom CNN Model with Image Manipulations\n",
    "\n",
    "To simulate an increase in a sample of image, you can apply image manipulation techniques: cropping, rotation, stretching, etc. Luckily Keras has some handy functions for us to apply these techniques to our mountain and forest example. You should be able to modify our image generator for the problem. Check out these resources to help you get started: \n",
    "\n",
    "1. [**Keras ImageGenerator Class**](https://keras.io/preprocessing/image/#imagedatagenerator-class) documentation for the tool that we need to use to augment our images.\n",
    "2. [**Building a powerful image classifier with very little data**](https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html) This is an essentially a tutorial on how to use the ImageGenerator class to create augmented images. You can essentially copy and paste the relevant code, though don't do that blindly! \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tzrg_BO_yojT"
   },
   "source": [
    "### Use ImageDataGenerator to create augmented data\n",
    "\n",
    "Use explore the parameters for ImageDataGenerator that will enable you to generate augment version of images that we already have. Here are some of the relevant parameters to help you get started. \n",
    "\n",
    "- rescale\n",
    "- shear_range\n",
    "- zoom_range\n",
    "- horizontal_flip\n",
    "\n",
    "### Only create augmented images for the training data. \n",
    "\n",
    "We want to be able to do a comparison with the same CNN model (or models) from above. \n",
    "\n",
    "In order to do that, we will augment the training data but not the validation data. Then we'll compare the accuracy and loss on the validation set. \n",
    "\n",
    "That way we are comparing the performance of the same model architecture on the same test set, the only different will be the augmented training data. Therefore, we'll be in a position to determine if augmenting our training data actually helped improve our model performance. \n",
    "\n",
    "This is an example of a controlled experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XKioBv3WtCBB"
   },
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "\n",
    "# ImageDataGenerator can rescale data from within \n",
    "max_pixel_val = 255.\n",
    "rescale = 1./max_pixel_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "id": "9EvRINLmyojU",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "05e142f4b4172598e62cfd36cb1ac2a2",
     "grade": false,
     "grade_id": "cell-0a8ffe613e7d391a",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "\n",
    "train_datagen_aug = ImageDataGenerator(\n",
    "#         rotation_range=40,\n",
    "#         width_shift_range=0.2,\n",
    "#         height_shift_range=0.2,\n",
    "        rescale=1./244,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": false,
    "id": "uIqluRyJyojU",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d40af8e7b09b4fccca8aec84f908e8ff",
     "grade": false,
     "grade_id": "cell-d458fa433ebcf555",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "outputId": "fe97026f-2d26-4573-f2e8-26305232025d"
   },
   "outputs": [],
   "source": [
    "# call the .flow_from_directory() method - save result to `train_data_gen_aug`\n",
    "# protip: be mindful of the parameters\n",
    "batch_size = 16\n",
    "train_data_gen_aug = train_datagen_aug.flow_from_directory(\n",
    "        train_dir,\n",
    "        target_size=(244, 244),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VyNBUG1kyojU"
   },
   "source": [
    "### Augment a Single Image\n",
    "\n",
    "Now that you have instantiate `ImageDataGenerator` object that created augmented images for the training set. Let's visual those augmented images to get a sense of what augmented images actually look like! \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O8W5zAgNiLvc"
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "id": "dClJbqw8yojV",
    "outputId": "1305434c-2ad7-4a0f-9e41-d05e6a5603a4"
   },
   "outputs": [],
   "source": [
    "# filename of image that we will augment\n",
    "# this is just one of 100's of training images to choose from\n",
    "# feel free to explore the training data directories and choose another image\n",
    "# this image was selected from the mountain images \n",
    "img_to_aug = \"art1131.jpg\"\n",
    "\n",
    "# replace with YOUR home directory name \n",
    "home_dir = \"makoa\"\n",
    "\n",
    "# create absolute file path to image file\n",
    "# path_to_single_img = os.path.normpath(\"C:/Users\\\\{0}\\\\.keras\\\\datasets\\\\data\\\\train\\\\mountain\\\\{1}\".format(home_dir, img_to_aug))\n",
    "path_to_single_img = \"./data/train/mountain/{1}\".format(home_dir, img_to_aug)\n",
    "# path_to_single_img = os.path.normpath(\"C://Users/{0}/Documents/Lambda/Unit 4/DS-Unit-4-Sprint-3-Deep-Learning/module2-convolutional-neural-networks/data/train/mountain/{1}\".format(home_dir, img_to_aug))\n",
    "path_to_single_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 385
    },
    "id": "udoC3875yojV",
    "outputId": "88708695-9278-4aa8-f6bb-1a79169f79c5"
   },
   "outputs": [],
   "source": [
    "# load in image from file and reshape\n",
    "img = load_img(path_to_single_img)\n",
    "x = img_to_array(img) \n",
    "x = x.reshape((1,) + x.shape)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZSFfyvKtyojV"
   },
   "source": [
    "Create a temporary director to store the augmented images that we will create in order to visualize. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iVp3hu2NyojV"
   },
   "outputs": [],
   "source": [
    "# this is a terminal command that we are running in the notebook by including a `!` \n",
    "# feel free to delete this temp dir after visualizing the aug images below\n",
    "# you only need to create this dir once\n",
    "!mkdir preview_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2lIctFY5yojW"
   },
   "source": [
    "Use the training data generator that we just created in order to create 20 augmented images of the same original image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oQAnXhdsyojW"
   },
   "outputs": [],
   "source": [
    "# the .flow() command below generates batches of randomly transformed images\n",
    "# and saves the results to the `preview_img` directory\n",
    "\n",
    "# create 20 aug images\n",
    "n_aug_imgs_to_create = 20\n",
    "i = 0\n",
    "for batch in train_datagen_aug.flow(x, \n",
    "                                    batch_size=1,\n",
    "                                    save_to_dir='preview_img', \n",
    "                                    save_prefix='art', \n",
    "                                    save_format='jpeg'):\n",
    "    i += 1\n",
    "    if i > n_aug_imgs_to_create:\n",
    "        break  # otherwise the generator would loop indefinitely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a0ftpoVUyojW"
   },
   "outputs": [],
   "source": [
    "# create list populated with augmented image filenames\n",
    "file_names = [f for f in listdir(\"preview_img\") if isfile(join(\"preview_img\", f))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0oop68ruyojW"
   },
   "outputs": [],
   "source": [
    "# load and prep images into a list \n",
    "aug_imgs = []\n",
    "for filename in file_names:\n",
    "\n",
    "    img = load_img(\"preview_img/{}\".format(filename)) \n",
    "    a_img = img_to_array(img)  \n",
    "    a_img = a_img.reshape((1,) + x.shape) \n",
    "    aug_imgs.append(a_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u40ekoIjyojW"
   },
   "outputs": [],
   "source": [
    "# notice that we are playing with a rank 5 tensor \n",
    "# we can ignore the first two numbers\n",
    "a_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3ovsUfbxyojX"
   },
   "outputs": [],
   "source": [
    "# the last 3 numbers have the actual image data\n",
    "# (num 1, num 2, num 3) = (img height, img width, color channels)\n",
    "a_img[0][0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lJBfvdbAyojX"
   },
   "source": [
    "### Visualize Augmented Images\n",
    "\n",
    "Notice that the augmented images are really just the original image with slight changes. One image might be a flipped with respect to the y-axis, or shifted along the x or y axis, or the right hand side might be clipped, or the image might be scaled up or down, or some combination of changes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sf0UotK0yojX"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(20,20))\n",
    "\n",
    "for i, a_img in enumerate(aug_imgs):\n",
    "    plt.subplot(5,5,i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(a_img[0][0]/255.)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LDuUNlwvyojX"
   },
   "source": [
    "Now the real question is does any of this ultimately matter? Do these changes actually help our model's ability to learn and generalize better? Well, let's go ahead and run that experiment. \n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1x8YFAi_yojX"
   },
   "source": [
    "## Re-train your custom CNN model using the augment dataset\n",
    "\n",
    "Now that we have created a data generator that creates augmented versions of the training images (and not the validation images). We can create a new instance of our custom CNN model with the same architecture, same parameters such as batch size and epochs and see if using augmented data helps. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oPYzRm9CyojY"
   },
   "outputs": [],
   "source": [
    "aug_model = create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KTgeegwtyojY"
   },
   "outputs": [],
   "source": [
    "aug_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7j7UQ1fvyojY"
   },
   "outputs": [],
   "source": [
    "logdir = os.path.join(\"logs\", \"aug_model\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1upw9YxzyojY"
   },
   "outputs": [],
   "source": [
    "# Fit Model\n",
    "\n",
    "epochs = 10\n",
    "\n",
    "history = aug_model.fit(\n",
    "    train_data_gen_aug,\n",
    "    steps_per_epoch=total_train // batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=val_data_gen,\n",
    "    validation_steps=total_val // batch_size,\n",
    "    workers=10, # num should be 1 or 2 processors less than the total number of process on your machine \n",
    "    callbacks=[tensorboard_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bQODwf0uyojY"
   },
   "source": [
    "-----\n",
    "\n",
    "# Compare Model Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Mel5dXUsyojZ"
   },
   "outputs": [],
   "source": [
    "%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G0BDuX0ZyojZ"
   },
   "source": [
    "------\n",
    "\n",
    "### Time for Questions \n",
    "\n",
    "Take a look at the `epoch_accuracy` plot and answer the following questions. \n",
    "\n",
    "Optionally move the `Smoothing` slider all the way to zero to view the raw scores. \n",
    "\n",
    "By the way, your results may look different than your classmates depending on how you choose to build your custom CNN model. \n",
    "\n",
    "\n",
    "**Question 1:** Which of the three models performed the best? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "id": "vWIhc826yojZ",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c582761ccc143c5d248d27ce49160bb8",
     "grade": true,
     "grade_id": "cell-0e8a26fd93ff75d1",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GZ50nqHRyojZ"
   },
   "source": [
    "**Question 2:** Did augmenting the training data help our custom CNN model improve its score? If so why, if not why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "id": "j5kzYhcUyojZ",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "36700b3583a95d15b36e934bf8e61b02",
     "grade": true,
     "grade_id": "cell-05178550630857e1",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "16QYJk55yojZ"
   },
   "source": [
    "**Question 3:** Could one or more of the three models benefit from training on more than 10 epochs? If so why, if not why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "id": "zv7BqisNyoja",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5739b5ef24367658384ddbb226ab6756",
     "grade": true,
     "grade_id": "cell-ce4cf1e6eb96f202",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dciQzMYyyoja"
   },
   "source": [
    "**Question 4:** If you didn't use regularization for you custom CNN, do you think the baseline model and the aug model could improve their scores if regularization was used? If so why, if not why not?\n",
    "\n",
    "Consider reviewing your Sprint 2 Module Assginment 2 experimental results on regularization. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "id": "pl7Obi8Myoja",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "963bdf6b8a29e4d8166bef574ebe66d9",
     "grade": true,
     "grade_id": "cell-9d8c200f58160233",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zHmLj_FXyoja"
   },
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uT3UV3gap9H6"
   },
   "source": [
    "# Resources and Stretch Goals\n",
    "\n",
    "Stretch goals\n",
    "- Enhance your code to use classes/functions and accept terms to search and classes to look for in recognizing the downloaded images (e.g. download images of parties, recognize all that contain balloons)\n",
    "- Check out [other available pretrained networks](https://tfhub.dev), try some and compare\n",
    "- Image recognition/classification is somewhat solved, but *relationships* between entities and describing an image is not - check out some of the extended resources (e.g. [Visual Genome](https://visualgenome.org/)) on the topic\n",
    "- Transfer learning - using images you source yourself, [retrain a classifier](https://www.tensorflow.org/hub/tutorials/image_retraining) with a new category\n",
    "- (Not CNN related) Use [piexif](https://pypi.org/project/piexif/) to check out the metadata of images passed in to your system - see if they're from a national park! (Note - many images lack GPS metadata, so this won't work in most cases, but still cool)\n",
    "\n",
    "Resources\n",
    "- [Deep Residual Learning for Image Recognition](https://arxiv.org/abs/1512.03385) - influential paper (introduced ResNet)\n",
    "- [YOLO: Real-Time Object Detection](https://pjreddie.com/darknet/yolo/) - an influential convolution based object detection system, focused on inference speed (for applications to e.g. self driving vehicles)\n",
    "- [R-CNN, Fast R-CNN, Faster R-CNN, YOLO](https://towardsdatascience.com/r-cnn-fast-r-cnn-faster-r-cnn-yolo-object-detection-algorithms-36d53571365e) - comparison of object detection systems\n",
    "- [Common Objects in Context](http://cocodataset.org/) - a large-scale object detection, segmentation, and captioning dataset\n",
    "- [Visual Genome](https://visualgenome.org/) - a dataset, a knowledge base, an ongoing effort to connect structured image concepts to language"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "include_colab_link": true,
   "name": "LS_DS_432_Convolution_Neural_Networks_Assignment.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "nteract": {
   "version": "0.23.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
